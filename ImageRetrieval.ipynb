{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.io import imread_collection\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-sitting",
   "metadata": {},
   "source": [
    "# Importing images for trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset= np.array(imread_collection('/home/myron/Desktop/vision/Μέρος Β-2020-2021/DataBase/*.jpg'),dtype=np.float64)/255\n",
    "testset= np.array(imread_collection('/home/myron/Desktop/vision/Μέρος Β-2020-2021/test/*.jpg'),dtype=np.float64)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-metro",
   "metadata": {},
   "source": [
    "# Creating Vectors of 100x100x3 and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_n=trainset.reshape(100,3*100*100)\n",
    "testset_n=testset.reshape(11,3*100*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "trainset_norm = scaler.fit_transform(trainset_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-glenn",
   "metadata": {},
   "source": [
    "# PCA with 100,50,10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca100 = PCA(n_components=100)\n",
    "dataset100=pca100.fit_transform(trainset_norm)\n",
    "test100=pca100.transform(testset_n)\n",
    "\n",
    "pca50 = PCA(n_components=50)\n",
    "dataset50=pca50.fit_transform(trainset_norm)\n",
    "test50=pca50.transform(testset_n)\n",
    "\n",
    "pca10 = PCA(n_components=10)\n",
    "dataset10=pca10.fit_transform(trainset_norm)\n",
    "test10=pca10.transform(testset_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-warrior",
   "metadata": {},
   "source": [
    "# Variance kept for each PCA aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance kept with 100 principal components:{:.5f}'.format(sum(pca100.explained_variance_ratio_)))\n",
    "print('Variance kept with 50 principal components:{:.5f}'.format(sum(pca50.explained_variance_ratio_)))\n",
    "print('Variance kept with 10 principal components:{:.5f}'.format(sum(pca10.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-excess",
   "metadata": {},
   "source": [
    "# Finding the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindImages(target,dataset):\n",
    "    cor={}\n",
    "    for i,img in  enumerate(dataset):\n",
    "        #corr, _ = kendalltau(target, img)\n",
    "        corr, _ = spearmanr(target,img)\n",
    "        cor[i]=corr\n",
    "    return sorted(cor.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=[(pca100,dataset100,test100),(pca50,dataset50,test50),(pca10,dataset10,test10)]\n",
    "for p in pairs:\n",
    "    for k in range(11):\n",
    "        output=FindImages(p[2][k],p[1])\n",
    "        img=p[0].inverse_transform(p[1][output])\n",
    "        img=(scaler.inverse_transform(img).reshape(100,100,3) * 255).astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-advocacy",
   "metadata": {},
   "source": [
    "# Grayscale PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "gray_trainset=np.array([rgb2gray(img)for img in trainset])\n",
    "gray_testset=np.array([rgb2gray(img) for img in testset])\n",
    "\n",
    "trainset_g_n=gray_trainset.reshape(100,-1)\n",
    "testset_g_n=gray_testset.reshape(11,-1)\n",
    "\n",
    "scaler_g=StandardScaler()\n",
    "trainset_g_norm = scaler_g.fit_transform(trainset_g_n)\n",
    "\n",
    "pca100g = PCA(n_components=100)\n",
    "dataset100g=pca100g.fit_transform(trainset_g_norm )\n",
    "test100g=pca100g.transform(testset_g_n)\n",
    "\n",
    "pca50g = PCA(n_components=50)\n",
    "dataset50g=pca50g.fit_transform(trainset_g_norm)\n",
    "test50g=pca50g.transform(testset_g_n)\n",
    "\n",
    "pca10g = PCA(n_components=10)\n",
    "dataset10g=pca10g.fit_transform(trainset_g_norm)\n",
    "test10g=pca10g.transform(testset_g_n)\n",
    "\n",
    "print('Variance kept with 100 principal components:{:.5f}'.format(sum(pca100.explained_variance_ratio_)))\n",
    "print('Variance kept with 50 principal components:{:.5f}'.format(sum(pca50.explained_variance_ratio_)))\n",
    "print('Variance kept with 10 principal components:{:.5f}'.format(sum(pca10.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gray_testset:\n",
    "    plt.imshow(i,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=[(pca100g,dataset100g,test100g),(pca50g,dataset50g,test50g),(pca10g,dataset10g,test10g)]\n",
    "for p in pairs:\n",
    "    for k in range(11):\n",
    "        output=FindImages(p[2][k],p[1])\n",
    "        img=p[0].inverse_transform(p[1][output])\n",
    "        img=(scaler_g.inverse_transform(img).reshape(100,100) * 255).astype(np.uint8)\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-valve",
   "metadata": {},
   "source": [
    "# Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=3*100*100\n",
    "learning_rate=1e-4\n",
    "batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset=torch.tensor(trainset_n,dtype=torch.float)\n",
    "Testset=torch.tensor(testset_n,dtype=torch.float)\n",
    "dl_train=DataLoader(Trainset,batch_size,shuffle=True)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,SpaceSize):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size,SpaceSize),\n",
    "            nn.LeakyReLU(0.20))\n",
    "            \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(SpaceSize,input_size),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "    def forward(self, x):\n",
    "      x = self.encoder(x)\n",
    "      #print(x.shape)\n",
    "      x = self.decoder(x)\n",
    "      #print(x.shape)\n",
    "      return x\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model100=AutoEncoder(100).to(device)\n",
    "model50=AutoEncoder(50).to(device)\n",
    "model10=AutoEncoder(10).to(device)\n",
    "optimizer100 = torch.optim.Adam(model100.parameters(), lr=1e-4)\n",
    "optimizer50= torch.optim.Adam(model50.parameters(), lr=1e-4)\n",
    "optimizer10 = torch.optim.Adam(model10.parameters(), lr=1e-4)\n",
    "Error100,Error50,Error10=[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=2000\n",
    "for epoch in range(Epochs):\n",
    "    for data in dl_train:\n",
    "        data=data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model100(data)\n",
    "        loss = criterion(output,data)\n",
    "        # ===================backward====================\n",
    "        optimizer100.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer100.step()\n",
    "    # ===================log========================\n",
    "    if epoch%20==0:\n",
    "        Error100.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, Epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset100=model100.encoder(Trainset.to(device))\n",
    "for k in range(11):\n",
    "    target=model100.encoder(Testset.to(device))[k]\n",
    "    p=FindImages(target.detach().cpu(),dataset100.detach().cpu())\n",
    "    img=model100.decoder(dataset100[p]).detach().cpu().reshape(100,100,3)\n",
    "    img[img>1]=0\n",
    "    img[img<0]=0\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=2000\n",
    "for epoch in range(Epochs):\n",
    "    for data in dl_train:\n",
    "        data=data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model50(data)\n",
    "        loss = criterion(output,data)\n",
    "        # ===================backward====================\n",
    "        optimizer50.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer50.step()\n",
    "    # ===================log========================\n",
    "    if epoch%20==0:\n",
    "        Error50.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch , Epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset50=model50.encoder(Trainset.to(device))\n",
    "for k in range(11):\n",
    "    target=model50.encoder(Testset.to(device))[k]\n",
    "    p=FindImages(target.detach().cpu(),dataset50.detach().cpu())\n",
    "    img=model50.decoder(dataset50[p]).detach().cpu().reshape(100,100,3)\n",
    "    img[img>1]=0\n",
    "    img[img<0]=0\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=2000\n",
    "for epoch in range(Epochs):\n",
    "    for data in dl_train:\n",
    "        data=data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model10(data)\n",
    "        loss = criterion(output,data)\n",
    "        # ===================backward====================\n",
    "        optimizer10.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer10.step()\n",
    "    # ===================log========================\n",
    "    if epoch%20==0:\n",
    "        Error10.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, Epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset10=model10.encoder(Trainset.to(device))\n",
    "for k in range(11):\n",
    "    target=model10.encoder(Testset.to(device))[k]\n",
    "    p=FindImages(target.detach().cpu(),dataset10.detach().cpu())\n",
    "    img=model10.decoder(dataset10[p]).detach().cpu().reshape(100,100,3)\n",
    "    img[img>1]=0\n",
    "    img[img<0]=0\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[20*r for r in range(0,100)]\n",
    "plt.plot(x,Error10,'r',label='10')\n",
    "plt.plot(x,Error50,'g',label='50')\n",
    "plt.plot(x,Error100,'b',label='100')\n",
    "plt.title('Loss functions')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-energy",
   "metadata": {},
   "source": [
    "# Autoencoder with grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_trainset=np.array([rgb2gray(img)for img in trainset])\n",
    "gray_testset=np.array([rgb2gray(img) for img in testset])\n",
    "\n",
    "trainset_g_n=gray_trainset.reshape(100,100*100)\n",
    "testset_g_n=gray_testset.reshape(11,100*100)\n",
    "\n",
    "Trainset_g=torch.tensor(trainset_g_n,dtype=torch.float)\n",
    "Testset_g=torch.tensor(testset_g_n,dtype=torch.float)\n",
    "dl_train=DataLoader(Trainset_g,batch_size,shuffle=True)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size=100*100\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model100g=AutoEncoder(100).to(device)\n",
    "model50g=AutoEncoder(50).to(device)\n",
    "model10g=AutoEncoder(10).to(device)\n",
    "optimizer100g = torch.optim.Adam(model100g.parameters(), lr=1e-4)\n",
    "optimizer50g= torch.optim.Adam(model50g.parameters(), lr=1e-4)\n",
    "optimizer10g = torch.optim.Adam(model10g.parameters(), lr=1e-4)\n",
    "Error100g,Error50g,Error10g=[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=2000\n",
    "for epoch in range(Epochs):\n",
    "    for data in dl_train:\n",
    "        data=data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model100g(data)\n",
    "        loss = criterion(output,data)\n",
    "        # ===================backward====================\n",
    "        optimizer100g.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer100g.step()\n",
    "    # ===================log========================\n",
    "    if epoch%20==0:\n",
    "        Error100g.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, Epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset100=model100g.encoder(Trainset_g.to(device))\n",
    "for k in range(11):\n",
    "    target=model100g.encoder(Testset_g.to(device))[k]\n",
    "    p=FindImages(target.detach().cpu(),dataset100.detach().cpu())\n",
    "    img=model100g.decoder(dataset100[p]).detach().cpu().reshape(100,100)\n",
    "    img[img>1]=0\n",
    "    img[img<0]=0\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=2000\n",
    "for epoch in range(Epochs):\n",
    "    for data in dl_train:\n",
    "        data=data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model50g(data)\n",
    "        loss = criterion(output,data)\n",
    "        # ===================backward====================\n",
    "        optimizer50g.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer50g.step()\n",
    "    # ===================log========================\n",
    "    if epoch%20==0:\n",
    "        Error50g.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch , Epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset50=model50g.encoder(Trainset_g.to(device))\n",
    "for k in range(11):\n",
    "    target=model50g.encoder(Testset_g.to(device))[k]\n",
    "    p=FindImages(target.detach().cpu(),dataset50.detach().cpu())\n",
    "    img=model50g.decoder(dataset50[p]).detach().cpu().reshape(100,100)\n",
    "    img[img>1]=0\n",
    "    img[img<0]=0\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=2000\n",
    "for epoch in range(Epochs):\n",
    "    for data in dl_train:\n",
    "        data=data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model10g(data)\n",
    "        loss = criterion(output,data)\n",
    "        # ===================backward====================\n",
    "        optimizer10g.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optimizer10g.step()\n",
    "    # ===================log========================\n",
    "    if epoch%20==0:\n",
    "        Error10.append(loss.item())\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, Epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset10=model10g.encoder(Trainset_g.to(device))\n",
    "for k in range(11):\n",
    "    target=model10g.encoder(Testset_g.to(device))[k]\n",
    "    p=FindImages(target.detach().cpu(),dataset10.detach().cpu())\n",
    "    img=model10g.decoder(dataset10[p]).detach().cpu().reshape(100,100)\n",
    "    img[img>1]=0\n",
    "    img[img<0]=0\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
